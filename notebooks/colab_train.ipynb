{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "81559087",
   "metadata": {
    "id": "81559087"
   },
   "source": [
    "# MaiChart AI - Cloud Training (Colab & Kaggle)\n",
    "\n",
    "1. **Check GPU**: \n",
    "    - **Colab**: Runtime -> Change runtime type -> T4 GPU.\n",
    "    - **Kaggle**: Settings -> Accelerator -> T4 GPU (or P100).\n",
    "2. **Features**:\n",
    "    *   **Auto-Resume**: è‡ªåŠ¨å¯»æ‰¾æœ€æ–°çš„ `epoch_X.pt` å¹¶æ¥åŠ›è½®æ•°è®­ç»ƒã€‚\n",
    "    *   **Environment Aware**: è‡ªåŠ¨æ£€æµ‹ Colab æˆ– Kaggle ç¯å¢ƒå¹¶é…ç½®è·¯å¾„ã€‚\n",
    "    *   **Cloud Persistence**: Colab è‡ªåŠ¨æŒ‚è½½ Google Driveï¼ŒKaggle é»˜è®¤ä¿å­˜åˆ° Working Directoryã€‚\n",
    "    *   **Deep Integration**: è‡ªåŠ¨å¤„ç†æ•°æ®é›†è§£å‹ã€ä¾èµ–å®‰è£…åŠæ–­ç‚¹ç»­ä¼ ã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6e75374e",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "6e75374e",
    "outputId": "1f2d59a5-3316-4d12-cd24-2bc213b5a2e5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wed Jan 21 18:03:59 2026       \n",
      "+-----------------------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 550.54.15              Driver Version: 550.54.15      CUDA Version: 12.4     |\n",
      "|-----------------------------------------+------------------------+----------------------+\n",
      "| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |\n",
      "|                                         |                        |               MIG M. |\n",
      "|=========================================+========================+======================|\n",
      "|   0  Tesla T4                       Off |   00000000:00:04.0 Off |                    0 |\n",
      "| N/A   41C    P8              9W /   70W |       0MiB /  15360MiB |      0%      Default |\n",
      "|                                         |                        |                  N/A |\n",
      "+-----------------------------------------+------------------------+----------------------+\n",
      "                                                                                         \n",
      "+-----------------------------------------------------------------------------------------+\n",
      "| Processes:                                                                              |\n",
      "|  GPU   GI   CI        PID   Type   Process name                              GPU Memory |\n",
      "|        ID   ID                                                               Usage      |\n",
      "|=========================================================================================|\n",
      "|  No running processes found                                                             |\n",
      "+-----------------------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ZeLNxZRwMG1",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "4ZeLNxZRwMG1",
    "outputId": "bd803efb-e20e-4704-c36e-6ca39da11530"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/content\n",
      "Cloning into 'maimai-chat-ai'...\n",
      "remote: Enumerating objects: 1883, done.\u001b[K\n",
      "remote: Counting objects: 100% (1883/1883), done.\u001b[K\n",
      "remote: Compressing objects: 100% (1840/1840), done.\u001b[K\n",
      "remote: Total 1883 (delta 42), reused 1874 (delta 37), pack-reused 0 (from 0)\u001b[K\n",
      "Receiving objects: 100% (1883/1883), 4.39 MiB | 17.21 MiB/s, done.\n",
      "Resolving deltas: 100% (42/42), done.\n",
      "/content/maimai-chat-ai\n",
      "\n",
      "--- å½“å‰ç›®å½•ä¸‹çš„æ–‡ä»¶ ---\n",
      "check_cuda.py  GPU_TRAINING.md\t\t README.md\t   tests\n",
      "configs        IMPORT_TOOL_INSTALLED.md  requirements.txt  train_gpu.bat\n",
      "data\t       models\t\t\t scripts\t   train_gpu.py\n",
      "docs\t       notebooks\t\t src\t\t   train.ps1\n",
      "Requirement already satisfied: librosa>=0.10.0 in /usr/local/lib/python3.12/dist-packages (from -r requirements.txt (line 2)) (0.11.0)\n",
      "Requirement already satisfied: soundfile>=0.12.1 in /usr/local/lib/python3.12/dist-packages (from -r requirements.txt (line 3)) (0.13.1)\n",
      "Requirement already satisfied: numpy>=1.24.0 in /usr/local/lib/python3.12/dist-packages (from -r requirements.txt (line 4)) (2.0.2)\n",
      "Requirement already satisfied: scipy>=1.10.0 in /usr/local/lib/python3.12/dist-packages (from -r requirements.txt (line 5)) (1.16.3)\n",
      "Requirement already satisfied: torch>=2.0.0 in /usr/local/lib/python3.12/dist-packages (from -r requirements.txt (line 9)) (2.9.0+cu126)\n",
      "Requirement already satisfied: transformers>=4.30.0 in /usr/local/lib/python3.12/dist-packages (from -r requirements.txt (line 10)) (4.57.6)\n",
      "Requirement already satisfied: einops>=0.6.1 in /usr/local/lib/python3.12/dist-packages (from -r requirements.txt (line 11)) (0.8.1)\n",
      "Collecting flash-attn>=2.0.0 (from -r requirements.txt (line 12))\n",
      "  Downloading flash_attn-2.8.3.tar.gz (8.4 MB)\n",
      "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m8.4/8.4 MB\u001b[0m \u001b[31m86.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "Requirement already satisfied: pandas>=2.0.0 in /usr/local/lib/python3.12/dist-packages (from -r requirements.txt (line 15)) (2.2.2)\n",
      "Requirement already satisfied: tqdm>=4.65.0 in /usr/local/lib/python3.12/dist-packages (from -r requirements.txt (line 16)) (4.67.1)\n",
      "Requirement already satisfied: datasets>=2.12.0 in /usr/local/lib/python3.12/dist-packages (from -r requirements.txt (line 17)) (4.0.0)\n",
      "Requirement already satisfied: tokenizers>=0.13.0 in /usr/local/lib/python3.12/dist-packages (from -r requirements.txt (line 18)) (0.22.2)\n",
      "Requirement already satisfied: matplotlib>=3.7.0 in /usr/local/lib/python3.12/dist-packages (from -r requirements.txt (line 21)) (3.10.0)\n",
      "Requirement already satisfied: seaborn>=0.12.0 in /usr/local/lib/python3.12/dist-packages (from -r requirements.txt (line 22)) (0.13.2)\n",
      "Requirement already satisfied: tensorboard>=2.13.0 in /usr/local/lib/python3.12/dist-packages (from -r requirements.txt (line 23)) (2.19.0)\n",
      "Requirement already satisfied: wandb>=0.15.0 in /usr/local/lib/python3.12/dist-packages (from -r requirements.txt (line 24)) (0.24.0)\n",
      "Requirement already satisfied: pyyaml>=6.0 in /usr/local/lib/python3.12/dist-packages (from -r requirements.txt (line 27)) (6.0.3)\n",
      "Collecting hydra-core>=1.3.0 (from -r requirements.txt (line 28))\n",
      "  Downloading hydra_core-1.3.2-py3-none-any.whl.metadata (5.5 kB)\n",
      "Requirement already satisfied: python-dotenv>=1.0.0 in /usr/local/lib/python3.12/dist-packages (from -r requirements.txt (line 29)) (1.2.1)\n",
      "Requirement already satisfied: rich>=13.0.0 in /usr/local/lib/python3.12/dist-packages (from -r requirements.txt (line 30)) (13.9.4)\n",
      "Requirement already satisfied: pytest>=7.3.0 in /usr/local/lib/python3.12/dist-packages (from -r requirements.txt (line 33)) (8.4.2)\n",
      "Collecting black>=23.3.0 (from -r requirements.txt (line 34))\n",
      "  Downloading black-26.1.0-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl.metadata (88 kB)\n",
      "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m88.9/88.9 kB\u001b[0m \u001b[31m9.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting isort>=5.12.0 (from -r requirements.txt (line 35))\n",
      "  Downloading isort-7.0.0-py3-none-any.whl.metadata (11 kB)\n",
      "Requirement already satisfied: audioread>=2.1.9 in /usr/local/lib/python3.12/dist-packages (from librosa>=0.10.0->-r requirements.txt (line 2)) (3.1.0)\n",
      "Requirement already satisfied: numba>=0.51.0 in /usr/local/lib/python3.12/dist-packages (from librosa>=0.10.0->-r requirements.txt (line 2)) (0.60.0)\n",
      "Requirement already satisfied: scikit-learn>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from librosa>=0.10.0->-r requirements.txt (line 2)) (1.6.1)\n",
      "Requirement already satisfied: joblib>=1.0 in /usr/local/lib/python3.12/dist-packages (from librosa>=0.10.0->-r requirements.txt (line 2)) (1.5.3)\n",
      "Requirement already satisfied: decorator>=4.3.0 in /usr/local/lib/python3.12/dist-packages (from librosa>=0.10.0->-r requirements.txt (line 2)) (4.4.2)\n",
      "Requirement already satisfied: pooch>=1.1 in /usr/local/lib/python3.12/dist-packages (from librosa>=0.10.0->-r requirements.txt (line 2)) (1.8.2)\n",
      "Requirement already satisfied: soxr>=0.3.2 in /usr/local/lib/python3.12/dist-packages (from librosa>=0.10.0->-r requirements.txt (line 2)) (1.0.0)\n",
      "Requirement already satisfied: typing_extensions>=4.1.1 in /usr/local/lib/python3.12/dist-packages (from librosa>=0.10.0->-r requirements.txt (line 2)) (4.15.0)\n",
      "Requirement already satisfied: lazy_loader>=0.1 in /usr/local/lib/python3.12/dist-packages (from librosa>=0.10.0->-r requirements.txt (line 2)) (0.4)\n",
      "Requirement already satisfied: msgpack>=1.0 in /usr/local/lib/python3.12/dist-packages (from librosa>=0.10.0->-r requirements.txt (line 2)) (1.1.2)\n",
      "Requirement already satisfied: cffi>=1.0 in /usr/local/lib/python3.12/dist-packages (from soundfile>=0.12.1->-r requirements.txt (line 3)) (2.0.0)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->-r requirements.txt (line 9)) (3.20.3)\n",
      "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->-r requirements.txt (line 9)) (75.2.0)\n",
      "Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->-r requirements.txt (line 9)) (1.14.0)\n",
      "Requirement already satisfied: networkx>=2.5.1 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->-r requirements.txt (line 9)) (3.6.1)\n",
      "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->-r requirements.txt (line 9)) (3.1.6)\n",
      "Requirement already satisfied: fsspec>=0.8.5 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->-r requirements.txt (line 9)) (2025.3.0)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->-r requirements.txt (line 9)) (12.6.77)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->-r requirements.txt (line 9)) (12.6.77)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->-r requirements.txt (line 9)) (12.6.80)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->-r requirements.txt (line 9)) (9.10.2.21)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->-r requirements.txt (line 9)) (12.6.4.1)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->-r requirements.txt (line 9)) (11.3.0.4)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->-r requirements.txt (line 9)) (10.3.7.77)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->-r requirements.txt (line 9)) (11.7.1.2)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->-r requirements.txt (line 9)) (12.5.4.2)\n",
      "Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->-r requirements.txt (line 9)) (0.7.1)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.27.5 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->-r requirements.txt (line 9)) (2.27.5)\n",
      "Requirement already satisfied: nvidia-nvshmem-cu12==3.3.20 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->-r requirements.txt (line 9)) (3.3.20)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->-r requirements.txt (line 9)) (12.6.77)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->-r requirements.txt (line 9)) (12.6.85)\n",
      "Requirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->-r requirements.txt (line 9)) (1.11.1.6)\n",
      "Requirement already satisfied: triton==3.5.0 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->-r requirements.txt (line 9)) (3.5.0)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.34.0 in /usr/local/lib/python3.12/dist-packages (from transformers>=4.30.0->-r requirements.txt (line 10)) (0.36.0)\n",
      "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.12/dist-packages (from transformers>=4.30.0->-r requirements.txt (line 10)) (25.0)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.12/dist-packages (from transformers>=4.30.0->-r requirements.txt (line 10)) (2025.11.3)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (from transformers>=4.30.0->-r requirements.txt (line 10)) (2.32.4)\n",
      "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.12/dist-packages (from transformers>=4.30.0->-r requirements.txt (line 10)) (0.7.0)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.12/dist-packages (from pandas>=2.0.0->-r requirements.txt (line 15)) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas>=2.0.0->-r requirements.txt (line 15)) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas>=2.0.0->-r requirements.txt (line 15)) (2025.3)\n",
      "Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.12/dist-packages (from datasets>=2.12.0->-r requirements.txt (line 17)) (18.1.0)\n",
      "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /usr/local/lib/python3.12/dist-packages (from datasets>=2.12.0->-r requirements.txt (line 17)) (0.3.8)\n",
      "Requirement already satisfied: xxhash in /usr/local/lib/python3.12/dist-packages (from datasets>=2.12.0->-r requirements.txt (line 17)) (3.6.0)\n",
      "Requirement already satisfied: multiprocess<0.70.17 in /usr/local/lib/python3.12/dist-packages (from datasets>=2.12.0->-r requirements.txt (line 17)) (0.70.16)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.7.0->-r requirements.txt (line 21)) (1.3.3)\n",
      "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.7.0->-r requirements.txt (line 21)) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.7.0->-r requirements.txt (line 21)) (4.61.1)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.7.0->-r requirements.txt (line 21)) (1.4.9)\n",
      "Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.7.0->-r requirements.txt (line 21)) (11.3.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.7.0->-r requirements.txt (line 21)) (3.3.1)\n",
      "Requirement already satisfied: absl-py>=0.4 in /usr/local/lib/python3.12/dist-packages (from tensorboard>=2.13.0->-r requirements.txt (line 23)) (1.4.0)\n",
      "Requirement already satisfied: grpcio>=1.48.2 in /usr/local/lib/python3.12/dist-packages (from tensorboard>=2.13.0->-r requirements.txt (line 23)) (1.76.0)\n",
      "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.12/dist-packages (from tensorboard>=2.13.0->-r requirements.txt (line 23)) (3.10)\n",
      "Requirement already satisfied: protobuf!=4.24.0,>=3.19.6 in /usr/local/lib/python3.12/dist-packages (from tensorboard>=2.13.0->-r requirements.txt (line 23)) (5.29.5)\n",
      "Requirement already satisfied: six>1.9 in /usr/local/lib/python3.12/dist-packages (from tensorboard>=2.13.0->-r requirements.txt (line 23)) (1.17.0)\n",
      "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.12/dist-packages (from tensorboard>=2.13.0->-r requirements.txt (line 23)) (0.7.2)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.12/dist-packages (from tensorboard>=2.13.0->-r requirements.txt (line 23)) (3.1.5)\n",
      "Requirement already satisfied: click>=8.0.1 in /usr/local/lib/python3.12/dist-packages (from wandb>=0.15.0->-r requirements.txt (line 24)) (8.3.1)\n",
      "Requirement already satisfied: gitpython!=3.1.29,>=1.0.0 in /usr/local/lib/python3.12/dist-packages (from wandb>=0.15.0->-r requirements.txt (line 24)) (3.1.46)\n",
      "Requirement already satisfied: platformdirs in /usr/local/lib/python3.12/dist-packages (from wandb>=0.15.0->-r requirements.txt (line 24)) (4.5.1)\n",
      "Requirement already satisfied: pydantic<3 in /usr/local/lib/python3.12/dist-packages (from wandb>=0.15.0->-r requirements.txt (line 24)) (2.12.3)\n",
      "Requirement already satisfied: sentry-sdk>=2.0.0 in /usr/local/lib/python3.12/dist-packages (from wandb>=0.15.0->-r requirements.txt (line 24)) (2.49.0)\n",
      "Requirement already satisfied: omegaconf<2.4,>=2.2 in /usr/local/lib/python3.12/dist-packages (from hydra-core>=1.3.0->-r requirements.txt (line 28)) (2.3.0)\n",
      "Requirement already satisfied: antlr4-python3-runtime==4.9.* in /usr/local/lib/python3.12/dist-packages (from hydra-core>=1.3.0->-r requirements.txt (line 28)) (4.9.3)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.12/dist-packages (from rich>=13.0.0->-r requirements.txt (line 30)) (4.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.12/dist-packages (from rich>=13.0.0->-r requirements.txt (line 30)) (2.19.2)\n",
      "Requirement already satisfied: iniconfig>=1 in /usr/local/lib/python3.12/dist-packages (from pytest>=7.3.0->-r requirements.txt (line 33)) (2.3.0)\n",
      "Requirement already satisfied: pluggy<2,>=1.5 in /usr/local/lib/python3.12/dist-packages (from pytest>=7.3.0->-r requirements.txt (line 33)) (1.6.0)\n",
      "Collecting mypy-extensions>=0.4.3 (from black>=23.3.0->-r requirements.txt (line 34))\n",
      "  Downloading mypy_extensions-1.1.0-py3-none-any.whl.metadata (1.1 kB)\n",
      "Collecting pathspec>=1.0.0 (from black>=23.3.0->-r requirements.txt (line 34))\n",
      "  Downloading pathspec-1.0.3-py3-none-any.whl.metadata (13 kB)\n",
      "Collecting pytokens>=0.3.0 (from black>=23.3.0->-r requirements.txt (line 34))\n",
      "  Downloading pytokens-0.4.0-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl.metadata (3.8 kB)\n",
      "Requirement already satisfied: pycparser in /usr/local/lib/python3.12/dist-packages (from cffi>=1.0->soundfile>=0.12.1->-r requirements.txt (line 3)) (2.23)\n",
      "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /usr/local/lib/python3.12/dist-packages (from fsspec[http]<=2025.3.0,>=2023.1.0->datasets>=2.12.0->-r requirements.txt (line 17)) (3.13.3)\n",
      "Requirement already satisfied: gitdb<5,>=4.0.1 in /usr/local/lib/python3.12/dist-packages (from gitpython!=3.1.29,>=1.0.0->wandb>=0.15.0->-r requirements.txt (line 24)) (4.0.12)\n",
      "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<1.0,>=0.34.0->transformers>=4.30.0->-r requirements.txt (line 10)) (1.2.0)\n",
      "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.12/dist-packages (from markdown-it-py>=2.2.0->rich>=13.0.0->-r requirements.txt (line 30)) (0.1.2)\n",
      "Requirement already satisfied: llvmlite<0.44,>=0.43.0dev0 in /usr/local/lib/python3.12/dist-packages (from numba>=0.51.0->librosa>=0.10.0->-r requirements.txt (line 2)) (0.43.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.12/dist-packages (from pydantic<3->wandb>=0.15.0->-r requirements.txt (line 24)) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.41.4 in /usr/local/lib/python3.12/dist-packages (from pydantic<3->wandb>=0.15.0->-r requirements.txt (line 24)) (2.41.4)\n",
      "Requirement already satisfied: typing-inspection>=0.4.2 in /usr/local/lib/python3.12/dist-packages (from pydantic<3->wandb>=0.15.0->-r requirements.txt (line 24)) (0.4.2)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests->transformers>=4.30.0->-r requirements.txt (line 10)) (3.4.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests->transformers>=4.30.0->-r requirements.txt (line 10)) (3.11)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests->transformers>=4.30.0->-r requirements.txt (line 10)) (2.5.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests->transformers>=4.30.0->-r requirements.txt (line 10)) (2026.1.4)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn>=1.1.0->librosa>=0.10.0->-r requirements.txt (line 2)) (3.6.0)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch>=2.0.0->-r requirements.txt (line 9)) (1.3.0)\n",
      "Requirement already satisfied: markupsafe>=2.1.1 in /usr/local/lib/python3.12/dist-packages (from werkzeug>=1.0.1->tensorboard>=2.13.0->-r requirements.txt (line 23)) (3.0.3)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets>=2.12.0->-r requirements.txt (line 17)) (2.6.1)\n",
      "Requirement already satisfied: aiosignal>=1.4.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets>=2.12.0->-r requirements.txt (line 17)) (1.4.0)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets>=2.12.0->-r requirements.txt (line 17)) (25.4.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets>=2.12.0->-r requirements.txt (line 17)) (1.8.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets>=2.12.0->-r requirements.txt (line 17)) (6.7.0)\n",
      "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets>=2.12.0->-r requirements.txt (line 17)) (0.4.1)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets>=2.12.0->-r requirements.txt (line 17)) (1.22.0)\n",
      "Requirement already satisfied: smmap<6,>=3.0.1 in /usr/local/lib/python3.12/dist-packages (from gitdb<5,>=4.0.1->gitpython!=3.1.29,>=1.0.0->wandb>=0.15.0->-r requirements.txt (line 24)) (5.0.2)\n",
      "Downloading hydra_core-1.3.2-py3-none-any.whl (154 kB)\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m154.5/154.5 kB\u001b[0m \u001b[31m14.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading black-26.1.0-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl (1.8 MB)\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m1.8/1.8 MB\u001b[0m \u001b[31m99.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading isort-7.0.0-py3-none-any.whl (94 kB)\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m94.7/94.7 kB\u001b[0m \u001b[31m11.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading mypy_extensions-1.1.0-py3-none-any.whl (5.0 kB)\n",
      "Downloading pathspec-1.0.3-py3-none-any.whl (55 kB)\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m55.0/55.0 kB\u001b[0m \u001b[31m5.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading pytokens-0.4.0-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl (268 kB)\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m268.9/268.9 kB\u001b[0m \u001b[31m30.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hBuilding wheels for collected packages: flash-attn\n",
      "  Building wheel for flash-attn (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "  Created wheel for flash-attn: filename=flash_attn-2.8.3-cp312-cp312-linux_x86_64.whl size=253780426 sha256=4e2f9e39313266b1544b68138b15b91ee6221eccf14f7902b7c6620351340810\n",
      "  Stored in directory: /root/.cache/pip/wheels/3d/59/46/f282c12c73dd4bb3c2e3fe199f1a0d0f8cec06df0cccfeee27\n",
      "Successfully built flash-attn\n",
      "Installing collected packages: pytokens, pathspec, mypy-extensions, isort, hydra-core, black, flash-attn\n",
      "Successfully installed black-26.1.0 flash-attn-2.8.3 hydra-core-1.3.2 isort-7.0.0 mypy-extensions-1.1.0 pathspec-1.0.3 pytokens-0.4.0\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import shutil\n",
    "import glob\n",
    "\n",
    "# ç¯å¢ƒæ£€æµ‹ / Environment Detection\n",
    "is_colab = 'google.colab' in str(get_ipython())\n",
    "is_kaggle = os.path.exists('/kaggle/working')\n",
    "\n",
    "if is_colab:\n",
    "    ROOT_PATH = '/content'\n",
    "    DEFAULT_ZIP_PATH = '/content/drive/MyDrive/maimai_data.zip'\n",
    "    DEFAULT_STORAGE_PATH = '/content/drive/MyDrive/maimai/models'\n",
    "elif is_kaggle:\n",
    "    ROOT_PATH = '/kaggle/working'\n",
    "    DEFAULT_ZIP_PATH = '/kaggle/input/maimai-data/maimai_data.zip'\n",
    "    DEFAULT_STORAGE_PATH = '/kaggle/working/models'\n",
    "else:\n",
    "    ROOT_PATH = os.getcwd()\n",
    "    DEFAULT_ZIP_PATH = './maimai_data.zip'\n",
    "    DEFAULT_STORAGE_PATH = './models'\n",
    "\n",
    "os.environ['ROOT_PATH'] = ROOT_PATH\n",
    "os.environ['PROJECT_PATH'] = os.path.join(ROOT_PATH, 'maimai-chat-ai')\n",
    "\n",
    "print(f\"Detected Environment: {'Colab' if is_colab else 'Kaggle' if is_kaggle else 'Local'}\")\n",
    "\n",
    "# 1. ç¡®ä¿å›åˆ°æ ¹ç›®å½•\n",
    "os.chdir(ROOT_PATH)\n",
    "if os.path.exists('maimai-chat-ai'):\n",
    "    print(\"Removing existing project folder...\")\n",
    "    shutil.rmtree('maimai-chat-ai')\n",
    "\n",
    "# 2. é‡æ–°å…‹éš†ä»“åº“\n",
    "print(\"Cloning repository...\")\n",
    "!git clone https://github.com/lvyirgil/maimai-chat-ai.git\n",
    "\n",
    "# éªŒè¯å…‹éš†æ˜¯å¦æˆåŠŸ\n",
    "if not os.path.exists('maimai-chat-ai'):\n",
    "    print(\"\\nâŒ Error: Failed to clone repository.\")\n",
    "    if is_kaggle:\n",
    "        print(\"ğŸ’¡ Hint: Please ensure 'Internet' is set to 'On' in the Kaggle sidebar settings.\")\n",
    "    raise FileNotFoundError(\"Project directory not found after git clone.\")\n",
    "\n",
    "# 3. è¿›å…¥æ–‡ä»¶å¤¹\n",
    "os.chdir(os.environ['PROJECT_PATH'])\n",
    "\n",
    "# 4. æ£€æŸ¥æ–‡ä»¶åˆ—è¡¨\n",
    "print(\"\\n--- Project Files ---\")\n",
    "!ls\n",
    "\n",
    "# 5. å®‰è£…ä¾èµ–\n",
    "if os.path.exists('requirements.txt'):\n",
    "    !pip install -r requirements.txt\n",
    "else:\n",
    "    print(\"\\nâŒ Error: requirements.txt not found.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "481131be",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "481131be",
    "outputId": "a226c280-2221-40c2-d5b4-6f13ce14a03a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "æ­£åœ¨å¼ºåŠ›è§£å‹ä¸­ï¼Œè¯·ç¨åï¼ˆ4.6GB å¯èƒ½éœ€è¦ 2-3 åˆ†é’Ÿï¼‰...\n",
      "âœ… è§£å‹å®Œæˆï¼\n",
      "å½“å‰éŸ³é¢‘æ•°: 1757\n",
      "å½“å‰è°±é¢æ•°: 1810\n"
     ]
    }
   ],
   "source": [
    "import zipfile\n",
    "import os\n",
    "import shutil\n",
    "import glob\n",
    "\n",
    "# å°è¯•è‡ªåŠ¨å®šä½ zip æ–‡ä»¶\n",
    "zip_path = DEFAULT_ZIP_PATH\n",
    "processed_zip_path = '/content/drive/MyDrive/processed_data.zip' if is_colab else './processed_data.zip'\n",
    "skip_preprocess = False\n",
    "\n",
    "# 1. ä¼˜å…ˆæ£€æŸ¥æ˜¯å¦å­˜åœ¨é¢„å¤„ç†è¿‡çš„æ•°æ®åŒ… (processed_data.zip)\n",
    "if os.path.exists(processed_zip_path):\n",
    "    print(f\"ğŸ“¦ å‘ç°å·²å¤„ç†çš„æ•°æ®åŒ…: {processed_zip_path}\")\n",
    "    processed_dir = os.path.join(os.environ['PROJECT_PATH'], 'data', 'processed')\n",
    "    os.makedirs(processed_dir, exist_ok=True)\n",
    "    \n",
    "    print(\"æ­£åœ¨è§£å‹é¢„å¤„ç†åçš„æ•°æ®åˆ° data/processed...\")\n",
    "    # ä½¿ç”¨ python zipfile ç¡®ä¿è·¨å¹³å°å…¼å®¹æ€§ï¼ˆè™½ç„¶ Colab/Kaggle éƒ½æ˜¯ Linuxï¼‰\n",
    "    with zipfile.ZipFile(processed_zip_path, 'r') as z:\n",
    "        z.extractall(processed_dir)\n",
    "        \n",
    "    print(f\"âœ… é¢„å¤„ç†æ•°æ®å·²å°±ç»ªï¼Œå½“å‰æ ·æœ¬æ•°: {len(os.listdir(processed_dir))}\")\n",
    "    skip_preprocess = True\n",
    "\n",
    "# 2. å¦‚æœæ²¡æœ‰é¢„å¤„ç†è¿‡çš„æ•°æ®ï¼Œåˆ™è§£å‹åŸå§‹æ•°æ®å¹¶å‡†å¤‡è¿›è¡Œé¢„å¤„ç†\n",
    "if not skip_preprocess:\n",
    "    if not os.path.exists(zip_path):\n",
    "        print(f\"âš ï¸ é»˜è®¤åŸå§‹æ•°æ®è·¯å¾„ {zip_path} æœªæ‰¾åˆ°ï¼Œå°è¯•æœç´¢...\")\n",
    "        if is_kaggle:\n",
    "            search_paths = glob.glob('/kaggle/input/**/*.zip', recursive=True)\n",
    "            if search_paths:\n",
    "                zip_path = search_paths[0]\n",
    "                print(f\"ğŸ” æ‰¾åˆ°åŸå§‹ Zip: {zip_path}\")\n",
    "        elif is_colab:\n",
    "            print(\"âŒ æœªæ‰¾åˆ° maimai_data.zip æˆ– processed_data.zipã€‚\")\n",
    "\n",
    "    target_base = os.path.join(os.environ['PROJECT_PATH'], 'data')\n",
    "\n",
    "    def force_unzip(path):\n",
    "        if not os.path.exists(path):\n",
    "            print(f\"âŒ é”™è¯¯ï¼šæœªæ‰¾åˆ° zip æ–‡ä»¶: {path}\")\n",
    "            return\n",
    "\n",
    "        # æ¸…ç†æ–‡ä»¶å¤¹\n",
    "        for d in ['audio', 'raw']:\n",
    "            shutil.rmtree(os.path.join(target_base, d), ignore_errors=True)\n",
    "            os.makedirs(os.path.join(target_base, d), exist_ok=True)\n",
    "\n",
    "        print(f\"æ­£åœ¨ä» {path} è§£å‹åŸå§‹æ•°æ®...\")\n",
    "        with zipfile.ZipFile(path, 'r') as z:\n",
    "            for info in z.infolist():\n",
    "                try:\n",
    "                    name = info.filename.encode('cp437').decode('gbk')\n",
    "                except:\n",
    "                    name = info.filename\n",
    "                name = name.replace('\\\\', '/')\n",
    "\n",
    "                if name.lower().endswith(('.mp3', '.wav', '.ogg', '.flac')):\n",
    "                    fname = os.path.basename(name)\n",
    "                    if fname:\n",
    "                        with z.open(info) as source, open(os.path.join(target_base, 'audio', fname), 'wb') as target:\n",
    "                            shutil.copyfileobj(source, target)\n",
    "                elif name.lower().endswith('.txt'):\n",
    "                    fname = os.path.basename(name)\n",
    "                    if fname:\n",
    "                        with z.open(info) as source, open(os.path.join(target_base, 'raw', fname), 'wb') as target:\n",
    "                            shutil.copyfileobj(source, target)\n",
    "\n",
    "        print(f\"âœ… åŸå§‹æ•°æ®æå–å®Œæˆï¼\")\n",
    "        print(f\"éŸ³é¢‘æ•°: {len(os.listdir(os.path.join(target_base, 'audio')))}, è°±é¢æ•°: {len(os.listdir(os.path.join(target_base, 'raw')))}\")\n",
    "\n",
    "    force_unzip(zip_path)\n",
    "\n",
    "# å°† skip_preprocess å¯¼å‡ºåˆ°ç¯å¢ƒå˜é‡ä¾›ä¸‹ä¸ªå•å…ƒæ ¼ä½¿ç”¨\n",
    "os.environ['SKIP_PREPROCESS'] = 'True' if skip_preprocess else 'False'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f56e522",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "3f56e522",
    "outputId": "daa37005-1b23-473a-be77-5d67cd7355f8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "è­¦å‘Š: æ‰¾ä¸åˆ° M@GICALâ˜†CURE! LOVE â™¥ SHOT! çš„éŸ³é¢‘æ–‡ä»¶\n",
      "è­¦å‘Š: æ‰¾ä¸åˆ° Freak Out Hr çš„éŸ³é¢‘æ–‡ä»¶\n",
      "è­¦å‘Š: æ‰¾ä¸åˆ° ãƒ‡ãƒ“ãƒ«ã˜ã‚ƒãªã„ã‚‚ã‚“ çš„éŸ³é¢‘æ–‡ä»¶\n",
      "è­¦å‘Š: æ‰¾ä¸åˆ° ã¦ã‚‰ã¦ã‚‰ çš„éŸ³é¢‘æ–‡ä»¶\n",
      "è­¦å‘Š: æ‰¾ä¸åˆ° Ref_rain (for 7th Heaven) çš„éŸ³é¢‘æ–‡ä»¶\n",
      "è­¦å‘Š: æ‰¾ä¸åˆ° Colorfull_Encounter çš„éŸ³é¢‘æ–‡ä»¶\n",
      "è­¦å‘Š: æ‰¾ä¸åˆ° ç¾å¤œæœˆé¡ çš„éŸ³é¢‘æ–‡ä»¶\n",
      "è­¦å‘Š: æ‰¾ä¸åˆ° MYTH Reï¼šLEASE çš„éŸ³é¢‘æ–‡ä»¶\n",
      "è­¦å‘Š: æ‰¾ä¸åˆ° ã¯ã„ã‚ˆã‚ã“ã‚“ã§ çš„éŸ³é¢‘æ–‡ä»¶\n",
      "è­¦å‘Š: æ‰¾ä¸åˆ° sÃ¸lips çš„éŸ³é¢‘æ–‡ä»¶\n",
      "è­¦å‘Š: æ‰¾ä¸åˆ° å»ƒå¢Ÿã«ã„ã¾ã™ã‚­ãƒ£ãƒ³ãƒšãƒ¼ãƒ³ çš„éŸ³é¢‘æ–‡ä»¶\n",
      "è­¦å‘Š: æ‰¾ä¸åˆ° Flashback çš„éŸ³é¢‘æ–‡ä»¶\n",
      "è­¦å‘Š: æ‰¾ä¸åˆ° Hainuwele çš„éŸ³é¢‘æ–‡ä»¶\n",
      "è­¦å‘Š: æ‰¾ä¸åˆ° æŠœéŒ¨ çš„éŸ³é¢‘æ–‡ä»¶\n",
      "è­¦å‘Š: æ‰¾ä¸åˆ° ãŠå‘ªã„ çš„éŸ³é¢‘æ–‡ä»¶\n",
      "è­¦å‘Š: æ‰¾ä¸åˆ° [å˜˜] ãƒ©ã‚¤ã‚¢ãƒ¼ãƒ€ãƒ³ã‚µãƒ¼ çš„éŸ³é¢‘æ–‡ä»¶\n",
      "è­¦å‘Š: æ‰¾ä¸åˆ° Chronomia çš„éŸ³é¢‘æ–‡ä»¶\n",
      "è­¦å‘Š: æ‰¾ä¸åˆ° ã‚ã„ãŸã„æ˜Ÿäºº çš„éŸ³é¢‘æ–‡ä»¶\n",
      "è­¦å‘Š: æ‰¾ä¸åˆ° HYP3RTRIBE çš„éŸ³é¢‘æ–‡ä»¶\n",
      "è­¦å‘Š: æ‰¾ä¸åˆ° ã‹°è²¬ä»»é›†åˆä½“ çš„éŸ³é¢‘æ–‡ä»¶\n",
      "è­¦å‘Š: æ‰¾ä¸åˆ° ã‚«ãƒ¼ãƒ‹ãƒã‚™ãƒ«ãƒãƒƒãƒ’ã‚šãƒ¼ çš„éŸ³é¢‘æ–‡ä»¶\n",
      "è­¦å‘Š: æ‰¾ä¸åˆ° å”± çš„éŸ³é¢‘æ–‡ä»¶\n",
      "è­¦å‘Š: æ‰¾ä¸åˆ° ã‚¢ãƒ³ãƒ€ãƒ¼ã‚­ãƒƒã‚º çš„éŸ³é¢‘æ–‡ä»¶\n",
      "è­¦å‘Š: æ‰¾ä¸åˆ° ãƒã‚ª çš„éŸ³é¢‘æ–‡ä»¶\n",
      "è­¦å‘Š: æ‰¾ä¸åˆ° ã—ã‚…ï½ã—ã‚“ï¼Ÿå¤‰èº«â˜†ãƒã‚«ã‚¤ã‚·ãƒ³zzZ çš„éŸ³é¢‘æ–‡ä»¶\n",
      "è­¦å‘Š: æ‰¾ä¸åˆ° Pixel Galaxy çš„éŸ³é¢‘æ–‡ä»¶\n",
      "è­¦å‘Š: æ‰¾ä¸åˆ° å‰å¤§ãªã‚‹æ‚ªé­”ã¯å®Ÿã¯å¤§å¤©ä½¿ãƒ‘ãƒˆãƒ©ã¡ã‚ƒã‚“æ§˜ãªã®ã ï¼ çš„éŸ³é¢‘æ–‡ä»¶\n",
      "è­¦å‘Š: æ‰¾ä¸åˆ° ãƒãƒ„ã‚±ãƒ³ã‚µãƒ³ãƒâ…¡ çš„éŸ³é¢‘æ–‡ä»¶\n",
      "è­¦å‘Š: æ‰¾ä¸åˆ° Beginning together! çš„éŸ³é¢‘æ–‡ä»¶\n",
      "è­¦å‘Š: æ‰¾ä¸åˆ° ãƒ“ãƒ“ãƒ‡ãƒ çš„éŸ³é¢‘æ–‡ä»¶\n",
      "è­¦å‘Š: æ‰¾ä¸åˆ° [X] äººãƒãƒ‹ã‚¢ çš„éŸ³é¢‘æ–‡ä»¶\n",
      "è­¦å‘Š: æ‰¾ä¸åˆ° Lover_s Trick çš„éŸ³é¢‘æ–‡ä»¶\n",
      "è­¦å‘Š: æ‰¾ä¸åˆ° ã¤ã¤ã‚™ã¿ãã‚™ã• çš„éŸ³é¢‘æ–‡ä»¶\n",
      "è­¦å‘Š: æ‰¾ä¸åˆ° ã‚µã‚¦ãƒ³ãƒˆã‚™ãƒ•ã‚šãƒ¬ã‚¤ãƒ¤ãƒ¼ çš„éŸ³é¢‘æ–‡ä»¶\n",
      "è­¦å‘Š: æ‰¾ä¸åˆ° ã‚·ã‚¹ã‚¿ãƒ¼ã‚·ã‚¹ã‚¿ãƒ¼ çš„éŸ³é¢‘æ–‡ä»¶\n",
      "è­¦å‘Š: æ‰¾ä¸åˆ° FLÎ›ME-FRÎ¦ST çš„éŸ³é¢‘æ–‡ä»¶\n",
      "è­¦å‘Š: æ‰¾ä¸åˆ° Divide et impera! çš„éŸ³é¢‘æ–‡ä»¶\n",
      "è­¦å‘Š: æ‰¾ä¸åˆ° ã‚·ãƒ¥ã‚¬ãƒ¼ãƒ›ãƒªãƒƒã‚¯ çš„éŸ³é¢‘æ–‡ä»¶\n",
      "è­¦å‘Š: æ‰¾ä¸åˆ° NO ONE YES MAN çš„éŸ³é¢‘æ–‡ä»¶\n",
      "è­¦å‘Š: æ‰¾ä¸åˆ° Bring it on çš„éŸ³é¢‘æ–‡ä»¶\n",
      "è­¦å‘Š: æ‰¾ä¸åˆ° Shining Ray ï½åƒ•ã‚‰ã®çµ†ï½ çš„éŸ³é¢‘æ–‡ä»¶\n",
      "è­¦å‘Š: æ‰¾ä¸åˆ° [å”] å¤ªé™½ç³»ãƒ†ã‚™ã‚¹ã‚³ çš„éŸ³é¢‘æ–‡ä»¶\n",
      "è­¦å‘Š: æ‰¾ä¸åˆ° è¶…æœ€çµ‚é¬¼ç•œå¦¹ãƒ•ãƒ©ãƒ³ãƒ‰ãƒ¼ãƒ«ãƒ»S çš„éŸ³é¢‘æ–‡ä»¶\n",
      "è­¦å‘Š: æ‰¾ä¸åˆ° [è¦š] Hainuwele çš„éŸ³é¢‘æ–‡ä»¶\n",
      "è­¦å‘Š: æ‰¾ä¸åˆ° VOLT çš„éŸ³é¢‘æ–‡ä»¶\n",
      "è­¦å‘Š: æ‰¾ä¸åˆ° ãƒ†ãƒˆãƒªã‚¹ çš„éŸ³é¢‘æ–‡ä»¶\n",
      "è­¦å‘Š: æ‰¾ä¸åˆ° ç„¡é–“å«‰å¦¬åŠ‡å ´ã€666ã€ çš„éŸ³é¢‘æ–‡ä»¶\n",
      "è­¦å‘Š: æ‰¾ä¸åˆ° Cider P@rty çš„éŸ³é¢‘æ–‡ä»¶\n",
      "è­¦å‘Š: æ‰¾ä¸åˆ° Geranium çš„éŸ³é¢‘æ–‡ä»¶\n",
      "è­¦å‘Š: æ‰¾ä¸åˆ° Make Up Your World feat. ã‚­ãƒ§ãƒ³ã‚·ãƒ¼ã®Ciã¡ã‚ƒã‚“ & ã‚‰ã£ã·ã³ã¨ çš„éŸ³é¢‘æ–‡ä»¶\n",
      "è­¦å‘Š: æ‰¾ä¸åˆ° å‘½ãƒ†ã‚¹ãƒ†ã‚¹ çš„éŸ³é¢‘æ–‡ä»¶\n",
      "è­¦å‘Š: æ‰¾ä¸åˆ° æœ€ã£é«˜ã®ã‚¨ãƒ³ã‚¿ãƒ¡ã !! çš„éŸ³é¢‘æ–‡ä»¶\n",
      "è­¦å‘Š: æ‰¾ä¸åˆ° Eureka çš„éŸ³é¢‘æ–‡ä»¶\n",
      "æ‰¾åˆ° 1757 ä¸ªè°±é¢\n",
      "å¤„ç†è°±é¢:   1% 16/1757 [01:22<1:35:33,  3.29s/it][src/libmpg123/id3.c:process_extra():684] error: No extra frame text / valid description?\n",
      "[src/libmpg123/id3.c:process_extra():684] error: No extra frame text / valid description?\n",
      "å¤„ç†è°±é¢:  13% 237/1757 [13:14<1:22:15,  3.25s/it][src/libmpg123/id3.c:process_extra():684] error: No extra frame text / valid description?\n",
      "å¤„ç†è°±é¢:  23% 406/1757 [21:36<1:09:54,  3.11s/it][src/libmpg123/id3.c:process_extra():684] error: No extra frame text / valid description?\n",
      "[src/libmpg123/id3.c:process_extra():684] error: No extra frame text / valid description?\n",
      "å¤„ç†è°±é¢:  24% 421/1757 [22:22<1:11:43,  3.22s/it][src/libmpg123/id3.c:process_comment():587] error: No comment text / valid description?\n",
      "å¤„ç†è°±é¢:  37% 658/1757 [34:24<52:32,  2.87s/it][src/libmpg123/id3.c:process_extra():684] error: No extra frame text / valid description?\n",
      "å¤„ç†è°±é¢:  63% 1102/1757 [57:24<31:59,  2.93s/it][src/libmpg123/id3.c:process_extra():684] error: No extra frame text / valid description?\n",
      "å¤„ç†è°±é¢:  65% 1134/1757 [59:04<32:14,  3.10s/it][src/libmpg123/id3.c:process_extra():684] error: No extra frame text / valid description?\n",
      "[src/libmpg123/id3.c:process_extra():684] error: No extra frame text / valid description?\n",
      "å¤„ç†è°±é¢:  82% 1440/1757 [1:14:33<16:07,  3.05s/it][src/libmpg123/id3.c:process_extra():684] error: No extra frame text / valid description?\n",
      "å¤„ç†è°±é¢:  84% 1474/1757 [1:16:17<13:42,  2.91s/it][src/libmpg123/id3.c:process_comment():587] error: No comment text / valid description?\n",
      "å¤„ç†è°±é¢:  88% 1544/1757 [1:19:50<10:54,  3.07s/it][src/libmpg123/id3.c:process_extra():684] error: No extra frame text / valid description?\n",
      "[src/libmpg123/id3.c:process_extra():684] error: No extra frame text / valid description?\n",
      "å¤„ç†è°±é¢: 100% 1756/1757 [1:30:39<00:02,  2.93s/it][src/libmpg123/id3.c:process_comment():587] error: No comment text / valid description?\n",
      "[src/libmpg123/id3.c:process_comment():587] error: No comment text / valid description?\n",
      "å¤„ç†è°±é¢: 100% 1757/1757 [1:30:41<00:00,  3.10s/it]\n",
      "æˆåŠŸå¤„ç† 1757 ä¸ªæ ·æœ¬\n",
      "ä¿å­˜æ ·æœ¬: 100% 1757/1757 [05:40<00:00,  5.17it/s]\n",
      "æ•°æ®å·²ä¿å­˜åˆ° data/processed\n",
      "æ•°æ®é¢„å¤„ç†å®Œæˆ!\n"
     ]
    }
   ],
   "source": [
    "os.chdir(os.environ['PROJECT_PATH'])\n",
    "\n",
    "# å¦‚æœå·²ç»è§£å‹äº† processed_data.zipï¼Œåˆ™è·³è¿‡è¯¥æ­¥éª¤\n",
    "if os.environ.get('SKIP_PREPROCESS') == 'True':\n",
    "    print(\"â­ï¸ æ£€æµ‹åˆ°å·²å¤„ç†æ•°æ®ï¼Œè·³è¿‡é¢„å¤„ç†æ­¥éª¤ã€‚\")\n",
    "else:\n",
    "    print(\"ğŸš€ å¼€å§‹æ•°æ®é¢„å¤„ç†...\")\n",
    "    !python -m src.data.preprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4SYBt095dLRe",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "4SYBt095dLRe",
    "outputId": "bec7c57d-8c2a-4ed0-a23f-dae2445f0f7c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "æ­£åœ¨å»ºç«‹å®æ—¶åŒæ­¥è½¯é“¾æ¥...\n",
      "âœ… å®æ—¶åŒæ­¥å·²å°±ç»ªï¼šç°åœ¨æ¨¡å‹ä¿å­˜ä¼šç›´æ¥å†™å…¥ç½‘ç›˜ã€‚\n",
      "è½½å…¥é…ç½®æ–‡ä»¶: configs/default.yaml\n",
      "\n",
      "============================================================\n",
      "GPU ä¿¡æ¯\n",
      "============================================================\n",
      "âœ“ CUDA å¯ç”¨\n",
      "âœ“ GPU æ•°é‡: 1\n",
      "\n",
      "GPU 0: Tesla T4\n",
      "  - è®¡ç®—èƒ½åŠ›: 7.5\n",
      "  - æ€»æ˜¾å­˜: 14.7 GB\n",
      "  - å½“å‰æ˜¾å­˜å ç”¨: 0.0 GB\n",
      "\n",
      "âœ“ PyTorch ç‰ˆæœ¬: 2.9.0+cu126\n",
      "âœ“ æ··åˆç²¾åº¦: å¯ç”¨ (FP16)\n",
      "============================================================\n",
      "\n",
      "è®­ç»ƒé…ç½®:\n",
      "  - è®¾å¤‡: cuda\n",
      "  - Batch Size: 4\n",
      "  - å­¦ä¹ ç‡: 1e-4\n",
      "  - æ··åˆç²¾åº¦: å¯ç”¨\n",
      "  - æœ€å¤§è½®æ•°: 100\n",
      "  - æ¢¯åº¦ç´¯ç§¯æ­¥æ•°: 4\n",
      "\n",
      "âœ“ æ£€æµ‹åˆ° GPUï¼Œå¯ç”¨æ··åˆç²¾åº¦å’Œä¼˜åŒ–å‚æ•°\n",
      "åŠ è½½æ ·æœ¬: 100% 1757/1757 [00:52<00:00, 33.59it/s]\n",
      "åŠ è½½äº† 1757 ä¸ªæ ·æœ¬\n",
      "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/transformer.py:392: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.norm_first was True\n",
      "  warnings.warn(\n",
      "ä» /content/maimai-chat-ai/models/best.pt åŠ è½½æ£€æŸ¥ç‚¹ (epoch 5)\n",
      "å¼€å§‹è®­ç»ƒï¼Œè®¾å¤‡: cuda\n",
      "è®­ç»ƒé›†å¤§å°: 1405\n",
      "éªŒè¯é›†å¤§å°: 175\n",
      "Epoch 0:   0% 0/351 [00:00<?, ?it/s]/usr/local/lib/python3.12/dist-packages/torch/nn/functional.py:6044: UserWarning: Support for mismatched key_padding_mask and attn_mask is deprecated. Use same type for both instead.\n",
      "  warnings.warn(\n",
      "Epoch 0: 352it [09:17,  1.58s/it, loss=0.2331, lr=1.00e-04]\n",
      "Epoch 0: train_loss = 0.2534\n",
      "Validating: 44it [00:18,  2.37it/s]\n",
      "Epoch 0: val_loss = 0.2489\n",
      "æ£€æŸ¥ç‚¹å·²ä¿å­˜åˆ° models/best.pt\n",
      "Epoch 1:  31% 110/351 [02:56<06:26,  1.60s/it, loss=0.2553, lr=1.00e-04]"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import glob\n",
    "import shutil\n",
    "\n",
    "# 1. å®šä¹‰å­˜å‚¨è·¯å¾„\n",
    "drive_models_path = DEFAULT_STORAGE_PATH\n",
    "local_models_path = os.path.join(os.environ['PROJECT_PATH'], 'models')\n",
    "\n",
    "# 2. åªæœ‰åœ¨ Colab æ—¶æŒ‚è½½ç½‘ç›˜\n",
    "if is_colab:\n",
    "    if not os.path.exists('/content/drive'):\n",
    "        from google.colab import drive\n",
    "        drive.mount('/content/drive')\n",
    "    \n",
    "    # å»ºç«‹è½¯é“¾æ¥ï¼Œç¡®ä¿è®­ç»ƒå™¨èƒ½ç›´æ¥ä¿å­˜åˆ°ç½‘ç›˜\n",
    "    os.makedirs(drive_models_path, exist_ok=True)\n",
    "    if os.path.exists(local_models_path) and not os.path.islink(local_models_path):\n",
    "        print(\"Moving local models to Drive sync folder...\")\n",
    "        # ä½¿ç”¨ python å‘½ä»¤é¿å… shell å·®å¼‚\n",
    "        for f in glob.glob(f\"{local_models_path}/*\"):\n",
    "            dest = os.path.join(drive_models_path, os.path.basename(f))\n",
    "            if not os.path.exists(dest):\n",
    "                shutil.move(f, dest)\n",
    "        shutil.rmtree(local_models_path)\n",
    "    \n",
    "    if not os.path.islink(local_models_path):\n",
    "        os.symlink(drive_models_path, local_models_path)\n",
    "    print(f\"âœ… Colab åŒæ­¥å·²å°±ç»ª: {drive_models_path}\")\n",
    "\n",
    "elif is_kaggle:\n",
    "    os.makedirs(local_models_path, exist_ok=True)\n",
    "    print(f\"âœ… Kaggle æ¨¡å¼: æ¨¡å‹å°†ä¿å­˜åœ¨ {local_models_path}\")\n",
    "else:\n",
    "    os.makedirs(local_models_path, exist_ok=True)\n",
    "\n",
    "# 3. è‡ªåŠ¨å¯»æ‰¾æœ€æ–°çš„ epoch æ£€æŸ¥ç‚¹è¿›è¡Œæ¢å¤\n",
    "checkpoints = glob.glob(f\"{local_models_path}/epoch_*.pt\")\n",
    "latest_resume = \"\"\n",
    "if checkpoints:\n",
    "    try:\n",
    "        # æŒ‰ç…§æ•°å­—å¤§å°æ’åºæ‰¾åˆ°æœ€åä¸€ä¸ª epoch\n",
    "        latest_resume = max(checkpoints, key=lambda x: int(os.path.basename(x).split('_')[1].split('.')[0]))\n",
    "        print(f\"æ£€æµ‹åˆ°æœ€æ–°æ£€æŸ¥ç‚¹: {latest_resume}ï¼Œå°†ä»è¯¥è½®æ•°ç»§ç»­è®­ç»ƒã€‚\")\n",
    "    except:\n",
    "        pass\n",
    "        \n",
    "if not latest_resume and os.path.exists(f\"{local_models_path}/best.pt\"):\n",
    "    latest_resume = f\"{local_models_path}/best.pt\"\n",
    "    print(\"æœªæ‰¾åˆ° epoch æ£€æŸ¥ç‚¹ï¼Œä½†æ£€æµ‹åˆ° best.ptï¼Œå°†ä»æœ€ä½³çŠ¶æ€æ¢å¤ã€‚\")\n",
    "\n",
    "# 4. å¯åŠ¨è®­ç»ƒ\n",
    "os.chdir(os.environ['PROJECT_PATH'])\n",
    "resume_cmd = f\"--resume {latest_resume}\" if latest_resume else \"\"\n",
    "!python train_gpu.py --config configs/default.yaml {resume_cmd} --epochs 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ZtKVHWdJiTP",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "0ZtKVHWdJiTP",
    "outputId": "829fb1b3-d800-411b-ced7-88e1ea6d57fe"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "remote: Enumerating objects: 5, done.\u001b[K\n",
      "remote: Counting objects:  20% (1/5)\u001b[K\rremote: Counting objects:  40% (2/5)\u001b[K\rremote: Counting objects:  60% (3/5)\u001b[K\rremote: Counting objects:  80% (4/5)\u001b[K\rremote: Counting objects: 100% (5/5)\u001b[K\rremote: Counting objects: 100% (5/5), done.\u001b[K\n",
      "remote: Compressing objects: 100% (1/1)\u001b[K\rremote: Compressing objects: 100% (1/1), done.\u001b[K\n",
      "remote: Total 3 (delta 2), reused 3 (delta 2), pack-reused 0 (from 0)\u001b[K\n",
      "Unpacking objects:  33% (1/3)\rUnpacking objects:  66% (2/3)\rUnpacking objects: 100% (3/3)\rUnpacking objects: 100% (3/3), 401 bytes | 401.00 KiB/s, done.\n",
      "From https://github.com/lvyirgil/maimai-chat-ai\n",
      "   af80070..12043b4  main       -> origin/main\n",
      "HEAD is now at 12043b4 Add --resume argument support to train_gpu.py\n"
     ]
    }
   ],
   "source": [
    "os.chdir(os.environ['PROJECT_PATH'])\n",
    "!git fetch origin && git reset --hard origin/main"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
